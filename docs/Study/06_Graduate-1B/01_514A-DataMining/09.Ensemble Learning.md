---
sidebar_position: 9
id: Ensemble Learning
title: Ensemble Learning
tags:
  - Study
  - Graduate
  - Data Mining
---

## Ensemble Learning

### Intro - What is Ensemble Learning?

1. Train multiple models.
2. Predict with all trained models.
3. Combine predictions to make a final prediction.

### Bias-Variance Tradeoff

| 指标         | 定义                   | 现象       | 原因               |
|--------------|------------------------|------------|--------------------|
| Bias (偏差)  | E[ŷ ‒ y]              | 欠拟合     | 模型过于简单       |
| Variance (方差) | $ E[(ŷ ‒ \bar{ŷ})^2] $ | 过拟合     | 模型过于复杂       |


### Common Ensemble Methods

#### Stacking (堆叠泛化)
1. Level 0 model: 用原始数据分别训练多个模型
2. Level 1 model: 用Level 0的预测结果作为数据集，再训练一个模型

#### Bootstrapping (自助采样)
对原始数据集进行`有放回的`采样，生成size相同的新数据集

eg. 原始数据集[A, B, C, D, D, G]，采样后的数据集可能包括[A, A, B, D, D, G], [C, D, D, G, G, G] blabla...

#### Bagging (Bootstrap Aggregating)
1. 用Bootstrapping生成多个数据集
2. 用每个数据集训练一个模型
3. 最后将多个模型的预测结果进行`平均`(Regression)或`投票`(Classification)，以综合

-> 降低过拟合风险

#### Random Forest
1. 用Bootstapping生成`1个`数据集
  - 未出现在自举数据集中的样本，被称为**Out-of-Bag**样本，可用于评估树的精度
2. 用数据集和随机选择的 $ j $ 个特征 (共有 $ M $ 个特征) 生成一棵决策树
3. 重复1和2，生成多棵树，组成森林
4. 最后取所有树的预测结果进行`平均`(Regression)或`投票`(Classification)，以综合

#### Boosting
1. 用原始数据集训练一个模型，得到预测结果
2. 根据模型的表现，调整样本的权重 - 对预测错误的样本加大权重
3. 用调整后的数据集训练下一个模型
4. 重复1-3，生成多个模型
5. 最后将多个模型的预测结果进行`加权平均`(Regression)或`加权投票`(Classification)，以综合
  - 表现好的模型权重更大

#### AdaBoost
1. 训练一个stump (树桩：只有根和两个叶子，即一个决策的树)
2. 根据树桩的表现：
  - 基于性能加权树桩的投票
  - 根据模型的表现，调整样本的权重 - 对预测错误的样本加大权重
  - 归一化样本权重之和为1
3. 用调整后的数据集训练下一个stump
4. 重复1-3，生成多个stump
5. 预测，加权，综合

